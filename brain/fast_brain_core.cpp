/**
 * ðŸ§  MELVIN FAST BRAIN CORE IMPLEMENTATION
 * High-performance C++ implementation of brain operations
 */

#include "fast_brain_core.hpp"
#include <sqlite3.h>
#include <json/json.h>
#include <sstream>
#include <fstream>
#include <cstring>
#include <cmath>
#include <algorithm>
#include <execution>

namespace melvin {
namespace brain {

// Thread-local random number generator
thread_local std::mt19937 FastBrainCore::rng_(std::random_device{}());

// FastNode Implementation
FastNode::FastNode(NodeID node_id, NodeType node_type, const std::string& node_content)
    : id(node_id), type(node_type), content(node_content) {
    
    auto now = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()).count();
    last_activation.store(now);
    
    // Initialize embedding vector with random values (will be replaced by actual embeddings)
    embedding.resize(512);
    std::uniform_real_distribution<float> dist(-0.1f, 0.1f);
    for (auto& val : embedding) {
        val = dist(rng_);
    }
}

void FastNode::activate(float strength) noexcept {
    activation_strength.store(strength);
    activation_count.fetch_add(1);
    
    auto now = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()).count();
    last_activation.store(now);
    
    // Update firing rate with exponential moving average
    float current_rate = firing_rate.load();
    float new_rate = 0.9f * current_rate + 0.1f * strength;
    firing_rate.store(new_rate);
}

void FastNode::update_success_rate(bool success) noexcept {
    if (success) {
        chain_success_count.fetch_add(1);
    }
    
    uint32_t total_access = access_count.fetch_add(1) + 1;
    uint32_t successes = chain_success_count.load();
    
    float new_rate = static_cast<float>(successes) / total_access;
    success_rate.store(new_rate);
}

void FastNode::add_connection(NodeID other_id) noexcept {
    std::unique_lock<std::shared_mutex> lock(mutex);
    if (connections.insert(other_id).second) {
        connection_count.fetch_add(1);
    }
}

void FastNode::remove_connection(NodeID other_id) noexcept {
    std::unique_lock<std::shared_mutex> lock(mutex);
    if (connections.erase(other_id)) {
        connection_count.fetch_sub(1);
    }
}

bool FastNode::should_fragment() const noexcept {
    float conn_density = static_cast<float>(connection_count.load()) / std::max(1.0f, static_cast<float>(content.size()));
    return content.size() > 200 && conn_density < 1.0f && access_count.load() < 5;
}

bool FastNode::should_consolidate() const noexcept {
    return content.size() <= 50 && connection_count.load() > 200 && access_count.load() > 10;
}

bool FastNode::should_specialize() const noexcept {
    return connection_count.load() > 100 && access_count.load() > 20;
}

// FastConnection Implementation
FastConnection::FastConnection(ConnectionID conn_id, NodeID src, NodeID tgt, ConnectionType conn_type)
    : id(conn_id), source_id(src), target_id(tgt), type(conn_type) {
    
    auto now = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()).count();
    creation_time.store(now);
    last_coactivation.store(now);
}

void FastConnection::strengthen(float amount) noexcept {
    float current_weight = weight.load();
    float new_weight = std::min(10.0f, current_weight + amount);
    weight.store(new_weight);
}

void FastConnection::weaken(float amount) noexcept {
    float current_weight = weight.load();
    float new_weight = std::max(0.001f, current_weight - amount);
    weight.store(new_weight);
}

void FastConnection::coactivate() noexcept {
    coactivation_count.fetch_add(1);
    auto now = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()).count();
    last_coactivation.store(now);
}

// FastBrainCore Implementation
FastBrainCore::FastBrainCore() {
    // Pre-allocate memory pools for better performance
    node_pool_.reserve(10000);
    connection_pool_.reserve(100000);
    
    // Initialize type indices
    for (int i = 0; i < static_cast<int>(NodeType::SPECIALIZED) + 1; ++i) {
        nodes_by_type_[static_cast<NodeType>(i)] = std::vector<NodeID>();
        nodes_by_type_[static_cast<NodeType>(i)].reserve(1000);
    }
}

FastBrainCore::~FastBrainCore() {
    // Cleanup is handled by unique_ptr destructors
}

NodeID FastBrainCore::create_node(NodeType type, const std::string& content) {
    NodeID id = next_node_id_.fetch_add(1);
    
    auto node = std::make_unique<FastNode>(id, type, content);
    
    {
        std::unique_lock<std::shared_mutex> lock(global_mutex_);
        nodes_[id] = std::move(node);
        nodes_by_type_[type].push_back(id);
        connections_by_node_[id] = std::vector<ConnectionID>();
    }
    
    update_indices_after_node_creation(id);
    return id;
}

ConnectionID FastBrainCore::create_connection(NodeID source, NodeID target, ConnectionType type, Weight initial_weight) {
    ConnectionID id = next_connection_id_.fetch_add(1);
    
    auto connection = std::make_unique<FastConnection>(id, source, target, type);
    connection->weight.store(initial_weight);
    
    {
        std::unique_lock<std::shared_mutex> lock(global_mutex_);
        connections_[id] = std::move(connection);
        connections_by_node_[source].push_back(id);
        connections_by_node_[target].push_back(id);
        
        // Update node connection counts
        if (nodes_.find(source) != nodes_.end()) {
            nodes_[source]->add_connection(target);
        }
        if (nodes_.find(target) != nodes_.end()) {
            nodes_[target]->add_connection(source);
        }
    }
    
    total_connections_created_.fetch_add(1);
    update_indices_after_connection_creation(id);
    return id;
}

bool FastBrainCore::activate_node(NodeID id, float strength) noexcept {
    std::shared_lock<std::shared_mutex> lock(global_mutex_);
    
    auto it = nodes_.find(id);
    if (it == nodes_.end()) {
        return false;
    }
    
    it->second->activate(strength);
    total_activations_.fetch_add(1);
    return true;
}

std::vector<NodeID> FastBrainCore::search_nodes_simd(const std::string& query, size_t max_results) const {
    utils::HighResTimer timer;
    std::vector<NodeID> results;
    results.reserve(max_results);
    
    std::string query_lower = query;
    std::transform(query_lower.begin(), query_lower.end(), query_lower.begin(), ::tolower);
    
    std::shared_lock<std::shared_mutex> lock(global_mutex_);
    
    // Use parallel execution for large datasets
    std::vector<std::pair<NodeID, float>> candidates;
    candidates.reserve(nodes_.size());
    
    for (const auto& [node_id, node] : nodes_) {
        std::string content_lower = node->content;
        std::transform(content_lower.begin(), content_lower.end(), content_lower.begin(), ::tolower);
        
        // Fast string matching with SIMD-optimized contains check
        if (string_contains_simd(content_lower, query_lower)) {
            // Calculate relevance score
            float score = 1.0f;
            
            // Boost score for exact matches
            if (content_lower.find(query_lower) == 0) {
                score *= 2.0f;
            }
            
            // Boost score based on node performance
            score *= node->get_success_rate() + 0.1f;
            score *= std::log(node->get_connection_count() + 1);
            
            candidates.emplace_back(node_id, score);
        }
    }
    
    // Sort by relevance score
    std::sort(std::execution::par_unseq, candidates.begin(), candidates.end(),
              [](const auto& a, const auto& b) { return a.second > b.second; });
    
    // Extract top results
    size_t limit = std::min(max_results, candidates.size());
    for (size_t i = 0; i < limit; ++i) {
        results.push_back(candidates[i].first);
    }
    
    const_cast<FastBrainCore*>(this)->total_searches_.fetch_add(1);
    return results;
}

std::vector<NodeID> FastBrainCore::get_connected_nodes(NodeID id, size_t max_results) const {
    std::vector<NodeID> results;
    results.reserve(max_results);
    
    std::shared_lock<std::shared_mutex> lock(global_mutex_);
    
    auto node_it = nodes_.find(id);
    if (node_it == nodes_.end()) {
        return results;
    }
    
    auto conn_it = connections_by_node_.find(id);
    if (conn_it == connections_by_node_.end()) {
        return results;
    }
    
    // Collect connected nodes with their connection weights
    std::vector<std::pair<NodeID, Weight>> weighted_connections;
    
    for (ConnectionID conn_id : conn_it->second) {
        auto connection_it = connections_.find(conn_id);
        if (connection_it == connections_.end()) continue;
        
        const auto& conn = connection_it->second;
        NodeID other_id = (conn->source_id == id) ? conn->target_id : conn->source_id;
        
        weighted_connections.emplace_back(other_id, conn->get_weight());
    }
    
    // Sort by connection weight
    std::sort(weighted_connections.begin(), weighted_connections.end(),
              [](const auto& a, const auto& b) { return a.second > b.second; });
    
    // Extract top results
    size_t limit = std::min(max_results, weighted_connections.size());
    for (size_t i = 0; i < limit; ++i) {
        results.push_back(weighted_connections[i].first);
    }
    
    return results;
}

void FastBrainCore::hebbian_update_batch(const std::vector<NodeID>& active_nodes) noexcept {
    if (active_nodes.size() < 2) return;
    
    // Strengthen connections between all pairs of active nodes
    for (size_t i = 0; i < active_nodes.size(); ++i) {
        for (size_t j = i + 1; j < active_nodes.size(); ++j) {
            strengthen_coactivated_connections(active_nodes[i], active_nodes[j]);
        }
    }
}

void FastBrainCore::strengthen_coactivated_connections(NodeID node1, NodeID node2) noexcept {
    std::shared_lock<std::shared_mutex> lock(global_mutex_);
    
    // Find existing connection between nodes
    auto conn_it1 = connections_by_node_.find(node1);
    if (conn_it1 == connections_by_node_.end()) return;
    
    for (ConnectionID conn_id : conn_it1->second) {
        auto connection_it = connections_.find(conn_id);
        if (connection_it == connections_.end()) continue;
        
        const auto& conn = connection_it->second;
        if ((conn->source_id == node1 && conn->target_id == node2) ||
            (conn->source_id == node2 && conn->target_id == node1)) {
            
            conn->strengthen(0.01f);
            conn->coactivate();
            return;
        }
    }
    
    // If no connection exists, create one
    lock.unlock();
    create_connection(node1, node2, ConnectionType::HEBBIAN, 0.1f);
}

float FastBrainCore::calculate_similarity_simd(const EmbeddingVector& a, const EmbeddingVector& b) const noexcept {
    if (a.size() != b.size() || a.empty()) {
        return 0.0f;
    }
    
    return utils::cosine_similarity_simd(a.data(), b.data(), a.size());
}

std::vector<std::pair<NodeID, float>> FastBrainCore::find_similar_nodes(NodeID reference_id, size_t max_results) const {
    std::vector<std::pair<NodeID, float>> results;
    
    std::shared_lock<std::shared_mutex> lock(global_mutex_);
    
    auto ref_it = nodes_.find(reference_id);
    if (ref_it == nodes_.end()) {
        return results;
    }
    
    const auto& ref_embedding = ref_it->second->embedding;
    
    // Calculate similarities with all other nodes
    std::vector<std::pair<NodeID, float>> similarities;
    similarities.reserve(nodes_.size());
    
    for (const auto& [node_id, node] : nodes_) {
        if (node_id == reference_id) continue;
        
        float similarity = calculate_similarity_simd(ref_embedding, node->embedding);
        if (similarity > 0.1f) {  // Threshold for relevance
            similarities.emplace_back(node_id, similarity);
        }
    }
    
    // Sort by similarity
    std::sort(similarities.begin(), similarities.end(),
              [](const auto& a, const auto& b) { return a.second > b.second; });
    
    // Return top results
    size_t limit = std::min(max_results, similarities.size());
    results.assign(similarities.begin(), similarities.begin() + limit);
    
    return results;
}

FastBrainCore::PerformanceStats FastBrainCore::get_performance_stats() const noexcept {
    std::shared_lock<std::shared_mutex> lock(global_mutex_);
    
    PerformanceStats stats;
    stats.total_nodes = nodes_.size();
    stats.total_connections = connections_.size();
    stats.total_activations = total_activations_.load();
    stats.total_searches = total_searches_.load();
    stats.memory_usage_bytes = get_memory_usage();
    
    // Calculate average times (simplified)
    stats.avg_search_time_ms = 0.5;  // Would be calculated from actual measurements
    stats.avg_activation_time_ms = 0.001;
    stats.cache_hit_rate = 0.85;  // Would be calculated from cache statistics
    
    return stats;
}

size_t FastBrainCore::get_memory_usage() const noexcept {
    size_t total = 0;
    
    // Calculate node memory usage
    for (const auto& [id, node] : nodes_) {
        total += sizeof(FastNode);
        total += node->content.size();
        total += node->embedding.size() * sizeof(float);
        total += node->connections.size() * sizeof(NodeID);
    }
    
    // Calculate connection memory usage
    total += connections_.size() * sizeof(FastConnection);
    
    // Add index overhead
    total += nodes_by_type_.size() * sizeof(std::vector<NodeID>);
    total += connections_by_node_.size() * sizeof(std::vector<ConnectionID>);
    
    return total;
}

void FastBrainCore::update_indices_after_node_creation(NodeID id) noexcept {
    // Indices are updated in create_node, this is for additional optimizations
}

void FastBrainCore::update_indices_after_connection_creation(ConnectionID id) noexcept {
    // Indices are updated in create_connection, this is for additional optimizations
}

bool FastBrainCore::string_contains_simd(const std::string& haystack, const std::string& needle) const noexcept {
    // Fallback to standard library for now - SIMD implementation would be more complex
    return haystack.find(needle) != std::string::npos;
}

uint64_t FastBrainCore::hash_string_fast(const std::string& str) const noexcept {
    // Simple hash function - could be optimized with SIMD
    uint64_t hash = 14695981039346656037ULL;  // FNV offset basis
    for (char c : str) {
        hash ^= static_cast<uint64_t>(c);
        hash *= 1099511628211ULL;  // FNV prime
    }
    return hash;
}

// Utility functions implementation
namespace utils {

float dot_product_simd(const float* a, const float* b, size_t size) noexcept {
    float result = 0.0f;
    
#ifdef __AVX2__
    // AVX2 implementation for 8 floats at a time
    __m256 sum = _mm256_setzero_ps();
    size_t simd_size = size & ~7;  // Round down to multiple of 8
    
    for (size_t i = 0; i < simd_size; i += 8) {
        __m256 va = _mm256_loadu_ps(&a[i]);
        __m256 vb = _mm256_loadu_ps(&b[i]);
        sum = _mm256_fmadd_ps(va, vb, sum);
    }
    
    // Horizontal sum
    __m128 sum_high = _mm256_extractf128_ps(sum, 1);
    __m128 sum_low = _mm256_castps256_ps128(sum);
    sum_low = _mm_add_ps(sum_low, sum_high);
    sum_low = _mm_hadd_ps(sum_low, sum_low);
    sum_low = _mm_hadd_ps(sum_low, sum_low);
    result = _mm_cvtss_f32(sum_low);
    
    // Handle remaining elements
    for (size_t i = simd_size; i < size; ++i) {
        result += a[i] * b[i];
    }
#else
    // Fallback implementation
    for (size_t i = 0; i < size; ++i) {
        result += a[i] * b[i];
    }
#endif
    
    return result;
}

float cosine_similarity_simd(const float* a, const float* b, size_t size) noexcept {
    float dot = dot_product_simd(a, b, size);
    float norm_a = std::sqrt(dot_product_simd(a, a, size));
    float norm_b = std::sqrt(dot_product_simd(b, b, size));
    
    if (norm_a == 0.0f || norm_b == 0.0f) {
        return 0.0f;
    }
    
    return dot / (norm_a * norm_b);
}

std::vector<std::string> split_string_fast(const std::string& str, char delimiter) {
    std::vector<std::string> result;
    std::stringstream ss(str);
    std::string item;
    
    while (std::getline(ss, item, delimiter)) {
        if (!item.empty()) {
            result.push_back(item);
        }
    }
    
    return result;
}

} // namespace utils
} // namespace brain
} // namespace melvin
